{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98474bd",
   "metadata": {},
   "source": [
    "1. What is the purpose of the General Linear Model (GLM)?\n",
    "\n",
    "Ans :- The purpose of GLM is to create a linear relationship even if the relationship between dependent and independent variable is not linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0726cc0",
   "metadata": {},
   "source": [
    "    2. What are the key assumptions of the General Linear Model?\n",
    "\n",
    "        Ans: Below are the assumptions:\n",
    "                1. Independent and dependent variable should be linear relationship\n",
    "                2. There should not be any multicollinearity\n",
    "                3. Errors should be normally distributed\n",
    "                4. Error should have constant variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40373194",
   "metadata": {},
   "source": [
    "    3. How do you interpret the coefficients in a GLM?\n",
    "    \n",
    "    Ans: -Coefficients in GLM is multiplicative of the features or independent variable.\n",
    "           It can be positive or negative.\n",
    "           Positive :- when changes happen in the coefficients of any feature that mean that model will have positive change\n",
    "           Negative :- when changes happen in the coefficients of any feature that mean that model will have Negative change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871caf5",
   "metadata": {},
   "source": [
    "    4. What is the difference between a univariate and multivariate GLM?\n",
    "\n",
    "    Ans: Univariate GLM :- When GLM consist of single independent  variable \n",
    "        Multivariate GLM:- When GLM consist of multiple independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d601c",
   "metadata": {},
   "source": [
    "    5. Explain the concept of interaction effects in a GLM.\n",
    "    Ans: Changes in one variable is the reason for the change in other variable is known as interaction effects in a glm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26db8d",
   "metadata": {},
   "source": [
    "    6. How do you handle categorical predictors in a GLM?\n",
    "\n",
    "    Ans: Effective way to handle the categorical predictor in GLM is to convert it into a number.\n",
    "        Below is the method is used for this.\n",
    "        1. Label Encoder\n",
    "        2. One hot encoding(dummy method)\n",
    "        3. Bins to numbers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75213016",
   "metadata": {},
   "source": [
    "7. What is the purpose of the design matrix in a GLM?\n",
    "\n",
    "Ans :- Purpose of design matrix is that it help the model to train on the data conveniently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d449c03",
   "metadata": {},
   "source": [
    "8. How do you test the significance of predictors in a GLM?\n",
    "\n",
    "Ans:\n",
    "     We can check based on p-value, whether our predictor is significant or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765ae21",
   "metadata": {},
   "source": [
    "9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n",
    "\n",
    "        Ans :\n",
    "          Type 1- Type I Sums of Squares, or also called Sequential Sums of Squares,\n",
    "            assign variation to the different variables in a sequential order.\n",
    "        \n",
    "        Type II - The Type II Sums of Squares take a different approach in two ways. \n",
    "        First of all, the variation assigned to independent variable A is accounting for B and \n",
    "        the other way around the variation assigned to B is accounting for A. \n",
    "        Secondly, the Type II Sums of Squares do not take an interaction effect.\n",
    "\n",
    "        Type III - The Type III Sums of Squares are also called partial sums of squares again another way of computing Sums of Squares:\n",
    "            Like Type II, the Type III Sums of Squares are not sequential, so the order of specification does not matter.\n",
    "            Unlike Type II, the Type III Sums of Squares do specify an interaction effect.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f931afe",
   "metadata": {},
   "source": [
    "10. Explain the concept of deviance in a GLM.\n",
    "\n",
    "Ans :- Deviance refers to rule-breaking behaviour of some kind which fails to conform to the norms and\n",
    "    expectations of a particular society or social group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2bb391",
   "metadata": {},
   "source": [
    "11. What is regression analysis and what is its purpose?\n",
    "Ans :- Regression analysis is a method which shows relationship between two or more variables.\n",
    "     \n",
    "        Purpose: It needs to predict the new data after traing the model in \n",
    "            which it understands the relationship between those variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dbc8c",
   "metadata": {},
   "source": [
    "12. What is the difference between simple linear regression and multiple linear regression?\n",
    "\n",
    "\n",
    "        Ans: - Simple Linear Regression - It has one independent variable and one dependent variable\n",
    "               Multiple Linear Regression :- It has more than one independent varibale and one dependent variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4c843",
   "metadata": {},
   "source": [
    "13. How do you interpret the R-squared value in regression?\n",
    "\n",
    "Ans:-  R-squared means that how much variation of dependent variable  explained by independent variable.\n",
    "         R-squared = 1 - (RSS/TSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d39f05",
   "metadata": {},
   "source": [
    "14. What is the difference between correlation and regression?\n",
    "\n",
    "        Ans : \n",
    "            Correlation :- it tells about the relationship between two independent variable\n",
    "            Regression:- It tells the linear relationship between dependent and independent variable.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d6b80",
   "metadata": {},
   "source": [
    "15. What is the difference between the coefficients and the intercept in regression?\n",
    "\n",
    "    \n",
    "        Ans: linear regression equation - y = mx+c\n",
    "             Intercept(c): Mean of the relationship. When all x values becomes 0, then the existing value is called intercept\n",
    "            Coefficient - It is the multiplicative number of the feature or x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a2e05",
   "metadata": {},
   "source": [
    "16. How do you handle outliers in regression analysis?\n",
    "\n",
    "\n",
    "        Ans: - Below are the ways by which we can handle outliers\n",
    "               1.Dropping the outliers\n",
    "               2. Taking the bins for the data\n",
    "               3. Normalize the data\n",
    "               4. We can use new column having o for outlliers and 1 for rest.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c82d3",
   "metadata": {},
   "source": [
    "17. What is the difference between ridge regression and ordinary least squares regression?\n",
    "\n",
    "\n",
    "        Ans: Ridge regression is a model tuning method which is used for data which consist of multicollinearity\n",
    "             Ordinary Least squares regression : It is a method of finding the coefficient for linear regression which describes the realtionship between one or  more independent variable and one dependent variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c9c11",
   "metadata": {},
   "source": [
    "18. What is heteroscedasticity in regression and how does it affect the model?\n",
    "\n",
    "        Ans : \n",
    "            Heteroscedasticity is phenomenon in which the variance of error term is not same.\n",
    "            It makes the model less dependable as it doesnot follow a particular pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad1e3e",
   "metadata": {},
   "source": [
    "19. How do you handle multicollinearity in regression analysis?\n",
    "\n",
    "        Ans :-  Below are the methods from which we can handle the multicollinearity:-\n",
    "                1. Remove some highly correlated independent variable.\n",
    "                2. Linear combine the independent variables such as adding them together.\n",
    "                3. Partial least squares regression uses principal component Analysis to create a set of uncorrelated \n",
    "                   components to include in the model.\n",
    "                4. Lasso and Ridge regression are some of the technique which we can we use for removing the                                   multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c03bd",
   "metadata": {},
   "source": [
    "20. What is polynomial regression and when is it used?\n",
    "     \n",
    "\n",
    "         Ans: \n",
    "             Polynomial regression are the regression technique which is performed on the non linear data where it \n",
    "                        can capture the non linear relationship.\n",
    "            \n",
    "            It is used when linear model is not able to capture the complexity of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbe629",
   "metadata": {},
   "source": [
    "21. What is a loss function and what is its purpose in machine learning?\n",
    "\n",
    "Ans:- Loss function is a method to measure how our model work in terms of prediction.\n",
    "\n",
    "      It's pupose is to check how well our model works on the predicted value.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b5bf5",
   "metadata": {},
   "source": [
    "22. What is the difference between a convex and non-convex loss function?\n",
    "\n",
    " Ans:- Convex loss function has only one global  minima  but not any local minima.\n",
    " \n",
    "        Non convex function has many local minima "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c7920",
   "metadata": {},
   "source": [
    "23. What is mean squared error (MSE) and how is it calculated?\n",
    "\n",
    "Ans: MSE is loss function which is used to check how our model performing. It is majorly used in linear regression.\n",
    "    It's formula is \n",
    "    \n",
    "      MSE = 1/n(summation(y_actual - y_predicterd)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cc0c7",
   "metadata": {},
   "source": [
    "24. What is mean absolute error (MAE) and how is it calculated?\n",
    "Ans: MAE is a loss function which is used to measure the accuracy of the model. It is basically used in regression model.\n",
    "     \n",
    "    It's formula is \n",
    "    MAE = 1/n(summation |y_actual - y_pred|)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d785a5bc",
   "metadata": {},
   "source": [
    "25. What is log loss (cross-entropy loss) and how is it calculated?\n",
    "\n",
    "Ans : Log loss is a loss function that represents how much predicted value has deviated from actual value.\n",
    "      \n",
    "        Log Loss = 1/n * summation -((y_actual * log(y_actual) + ((1 - y_actual) * log(1- y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c933b",
   "metadata": {},
   "source": [
    "26. How do you choose the appropriate loss function for a given problem?\n",
    "\n",
    "Ans:\n",
    "\n",
    "\n",
    "     Loss function for regression :-\n",
    "        Mean Square Error / Quadratic Loss / L2 Loss\n",
    "        Mean Absolute Error / L1 Loss\n",
    "        Huber Loss / Smooth Mean Absolute Error\n",
    "        \n",
    "    Loss Function for Classification:\n",
    "        Binary Cross-Entropy Loss / Log Loss\n",
    "        Hinge Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46bab2",
   "metadata": {},
   "source": [
    "27. Explain the concept of regularization in the context of loss functions\n",
    "\n",
    "Ans :-\n",
    "    \n",
    "    Cost Function = Loss_function + regularization\n",
    "    \n",
    "    regularization :\n",
    "        Lasso(l1) : alpha * summation|weights|\n",
    "        Ridge(l2) : alpha * summation((weights)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b5ea9",
   "metadata": {},
   "source": [
    "28. What is Huber loss and how does it handle outliers?\n",
    "\n",
    "Ans: Huber loss is coombination of mean squared error and mean absolute error. It is used in rebust regression \n",
    "    where it is robust to outliers.\n",
    "    \n",
    "    Formula :\n",
    "        Cost function = 1/2 (y_actual - y_pred)**2  for |(y_actual - y_pred)| <= lamda\n",
    "                        lambda * (|(y_actual - y_pred)| -1/2 lambda)\n",
    "            \n",
    "        for large values, it is taking the absolute of the value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718d3bd",
   "metadata": {},
   "source": [
    "29. What is quantile loss and when is it used?\n",
    "\n",
    "Ans:\n",
    "    Machine learning algorithm aiming to predict a particular variable quantile use quantile loss as a loss function.\n",
    "    It's formula\n",
    "    Quantile loss =    { alpha * (y_actual - y_pred)\n",
    "                       {(1-alpha) * (y_actual - y_pred)\n",
    "                        \n",
    "                        where alpha is quantile needs to be predicted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e6b96",
   "metadata": {},
   "source": [
    "30. What is the difference between squared loss and absolute loss?\n",
    "\n",
    "Ans:  \n",
    "      Squared loss: It is not robust to outliers. It's formula is \n",
    "           MSE =  1/n(summation(y_actual - y_predicterd)**2)\n",
    "            \n",
    "     Absolute Loss :- It is robust to outliers. It's formula is given by \n",
    "        \n",
    "              MAE = 1/n(summation |y_actual - y_pred|)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed554a9a",
   "metadata": {},
   "source": [
    "31. What is an optimizer and what is its purpose in machine learning?\n",
    "\n",
    " An optimizer is algorithm or function that adepts the neural network attributes such as weight and bias\n",
    "    It'r purpose  to optimize the weight and bias so that the model predict the correct result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ae137",
   "metadata": {},
   "source": [
    "32. What is Gradient Descent (GD) and how does it work?\n",
    "\n",
    "        Ans: Gradient Descent is an iterative first order optimization algorithm used to find the\n",
    "            local minima or maxima of a givn function.\n",
    "    \n",
    "        This method is used to minimize the loss function.\n",
    "        Gradient Descent Algorithm iteratively calculates the next point using the gradient at the current position,\n",
    "        sacles it(by a learning rate) and substracts obtained value from the current position. It subtracts because we want \n",
    "        to minimize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a23152",
   "metadata": {},
   "source": [
    "33. What are the different variations of Gradient Descent?\n",
    "      \n",
    "        Ans:\n",
    "            1. Stochastic Grdient Descent(SGD)\n",
    "            2 Mini Batch SGD\n",
    "            3. Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50645351",
   "metadata": {},
   "source": [
    "34. What is the learning rate in GD and how do you choose an appropriate value?\n",
    "\n",
    "Ans:- \n",
    "\n",
    "      Learning decides how fast or slow we will move towards the optimal weight. \n",
    "      \n",
    "      Learning rate should be high otherwise it will miss the minimal value or it should not be too small such that it will \n",
    "      take more time to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf33d0",
   "metadata": {},
   "source": [
    "35. How does GD handle local optima in optimization problems?\n",
    " \n",
    "        Ans:-  To handle the local minima problem in optimization problem, we use SGD which will skip the local optima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539eabf4",
   "metadata": {},
   "source": [
    "36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?\n",
    "\n",
    "        Ans:- SGD is a variant of GD where it trains the data one by one in place of whole data.\n",
    "        In GD, we train on whole data while in SGD we train on single set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2695ae4",
   "metadata": {},
   "source": [
    "37. Explain the concept of batch size in GD and its impact on training.\n",
    "\n",
    "        Ans: While training the GD, we use to pass the whole data on which training occurs. However, it will take more time and space. TO overcome, we pass the data in batch(16,32,64) which will overcome the problem of time and space.\n",
    "        Because of this, model will be trained faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c50f1",
   "metadata": {},
   "source": [
    "38. What is the role of momentum in optimization algorithms?\n",
    "\n",
    "\n",
    "        Ans: -  Momentum helps to smooth out model parameter updates and lowers the influence of noisy gradients which can   assist the to enhance the convergence speed.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20e194",
   "metadata": {},
   "source": [
    "39. What is the difference between batch GD, mini-batch GD, and SGD?\n",
    " \n",
    "         Ans:\n",
    "         Batch GD :- In bacth GD, model trains on whole data.\n",
    "         Mini Batch GD : In Mini Batch GD, model runs on batches of data.\n",
    "         SGD : In SGD, model runs on a single set of data.\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc854d3",
   "metadata": {},
   "source": [
    "40. How does the learning rate affect the convergence of GD?\n",
    "\n",
    "Ans:\n",
    "      \n",
    "    If learning is high then the convergence will be faster and if it is small, it will take more time to convergence.\n",
    "    Note:  We should not give too high learning rate otherwise it will skip the optimal parmeters. \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2408de",
   "metadata": {},
   "outputs": [],
   "source": [
    "41. What is regularization and why is it used in machine learning?\n",
    "\n",
    "Ans:- Regularization is a method of adding the penalty to model when model is overfitting.\n",
    "    \n",
    "     It is used in machine learning when it is overfitting the data so that it can predict the correct results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e9568",
   "metadata": {},
   "source": [
    "42. What is the difference between L1 and L2 regularization?\n",
    "\n",
    "Ans:  L1(Lasso) : It is technique in which we add absolute value of model parameter to overcome the overfitting.\n",
    "        \n",
    "     L2(Ridge):- It is technique in which we add the square value of model parameter to overcome the overfitting.\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec94fb",
   "metadata": {},
   "source": [
    "43. Explain the concept of ridge regression and its role in regularization.\n",
    "\n",
    "Ans:-  Ridge regression is also known as l2. Here we add the square value of model paremater.\n",
    "    It's equation is :\n",
    "        lambda/2n * summation((W)**2)\n",
    "        \n",
    "        lambda - l2 penalty\n",
    "        W - parameter of the model\n",
    "        \n",
    "        If our model is overfitting, then we add penalty which is ridge regression to model to perform better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae6e21",
   "metadata": {},
   "source": [
    "44. What is the elastic net regularization and how does it combine L1 and L2 penalties?\n",
    "\n",
    "Ans: Elastic net regularization is the combination of l1 and l2. It uses the penalties from both l1 and l2 technique \n",
    "    to regularize the regression model.\n",
    "     \n",
    "    Elastic net regularization formula is :\n",
    "        lambda_1* summation(Weight) + lambda_2 * summation((Weight)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae2de2",
   "metadata": {},
   "source": [
    "45. How does regularization help prevent overfitting in machine learning models?\n",
    "\n",
    "Ans: In regularization, we shrink,regularize or constraint the parameter of the model towards zero.\n",
    "    So, by this way prevent model from overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b65af",
   "metadata": {},
   "source": [
    "46. What is early stopping and how does it relate to regularization?\n",
    "\n",
    "Ans:- Early stopping is a situation in which model stops early when the accuracy of the model is decreasing.\n",
    "    It is one of the simple method of regularization. \n",
    "    When model is traing and accuracy is decreasing, in this case we stop the model.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475b7a4",
   "metadata": {},
   "source": [
    "47. Explain the concept of dropout regularization in neural networks.\n",
    "\n",
    "Ans:\n",
    "    Dropout is a technique in deep learning, in whcih randomly selected neurons are ignored while training.\n",
    "    \n",
    "    It is one of the method which will stop the model from the overfitting.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba3cda",
   "metadata": {},
   "source": [
    "48. How do you choose the regularization parameter in a model?\n",
    "\n",
    "Ans:- \n",
    "    On training set data, we train the model on different parameter and we select the parameter for which it gives the best\n",
    "    result.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8560fb2",
   "metadata": {},
   "source": [
    "49. What is the difference between feature selection and regularization?\n",
    "\n",
    "Ans:\n",
    "    In Feature selection, we select those feature who are impacting more on target variable.\n",
    "    \n",
    "    Regularization : we are adding penalties to model which will shrink, constrain the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84244ee",
   "metadata": {},
   "source": [
    "50. What is the trade-off between bias and variance in regularized models?\n",
    "\n",
    "Ans:\n",
    "    When the model is too simple, then the bias is high and variance is low\n",
    "    and when model is too complex , then the variance is high and bias is low.\n",
    "    \n",
    "    So, we need to have a model such that bias amd variance is medium. This is known as tradeoff between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f94a0",
   "metadata": {},
   "source": [
    "51. What is Support Vector Machines (SVM) and how does it work?\n",
    "\n",
    "Ans: \n",
    "     SVM is machine learning algorithm which draws a hyperplane to seperate all the data points.\n",
    "    It has two marginal plane which is equi distant from the plane in opposite direction.\n",
    "    \n",
    "    It works by mapping the data points in higher plane and drawing the plane which separates those data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5534a4",
   "metadata": {},
   "source": [
    "52. How does the kernel trick work in SVM?\n",
    "\n",
    "Ans: Kernel trick is used to transform the data points from one plane to other plane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec477d1a",
   "metadata": {},
   "source": [
    "53. What are support vectors in SVM and why are they important?\n",
    "\n",
    "Ans: Support vectors are those data points which lies on the marginal plane.\n",
    "    \n",
    "    It influences the hyperplane. It is used to calculate the margin of classifier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7ac7c",
   "metadata": {},
   "source": [
    "54. Explain the concept of the margin in SVM and its impact on model performance.\n",
    "\n",
    "Ans : \n",
    "    \n",
    "    Margin is the distance between the hyper plane and support vector. \n",
    "    \n",
    "    When margin is more, model is considered good.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e901df",
   "metadata": {},
   "source": [
    "55. How do you handle unbalanced datasets in SVM?\n",
    "\n",
    "Ans:- Below are the methods by which unbalanced datasets are handled in svm\n",
    "    1. By increasing the weight for minimal target value \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acce07",
   "metadata": {},
   "source": [
    "56. What is the difference between linear SVM and non-linear SVM?\n",
    "\n",
    "Ans: \n",
    "    Linear SVM are used for linear separable data.\n",
    "    \n",
    "    For non linear separable data, we use kernel function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022a536",
   "metadata": {},
   "source": [
    "57. What is the role of C-parameter in SVM and how does it affect the decision boundary?\n",
    "\n",
    "Ans: C-parameter adds penalty for the misclassied data.\n",
    "    \n",
    "    \n",
    "    If c value is less,the penalty for misclassified points is low so a decision boundary with a large margin is chosen at the expense\n",
    "    of a greater number of misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159721df",
   "metadata": {},
   "source": [
    "58. Explain the concept of slack variables in SVM.\n",
    "\n",
    "Ans :- Slack variable are introduced in SVM to allow certain constraint to be violeted.\n",
    "     It means that certain data points will be allowed inside the margin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3e076",
   "metadata": {},
   "source": [
    "59. What is the difference between hard margin and soft margin in SVM?\n",
    "\n",
    "Ans:\n",
    "    Hard Margin - It means that there will be no data points between the margin plane and hyper plane.\n",
    "    \n",
    "    Soft Margin : It means that some data points will be allowed between the margin plane and hyper plane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73582743",
   "metadata": {},
   "source": [
    "60. How do you interpret the coefficients in an SVM model?\n",
    "\n",
    "Ans: Coefficients in a SVM model can be in positive and negative.\n",
    "    By this we can say that variable is going towards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "61. What is a decision tree and how does it work?\n",
    "\n",
    "Ans: A decision tree is one of the most powerful tools of supervised learning algorithms used \n",
    "     for both classification and regression tasks.\n",
    "        \n",
    "    A tree can be “learned” by splitting the source set into subsets based on Attribute Selection Measures. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb49265",
   "metadata": {},
   "outputs": [],
   "source": [
    "62. How do you make splits in a decision tree?\n",
    "\n",
    "Ans : Decision tree splits based on the Attribute Selection Measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "63. What are impurity measures (e.g., Gini index, entropy) and how are they used in decision\n",
    "trees?\n",
    "\n",
    "Ans:-\n",
    "\n",
    "    Gini Index :- It is the measure of randomness or impurity or entropy in the values in the dataset\n",
    "        \n",
    "    Entropy :- It is measure of disorder or impurity in a node\n",
    "        \n",
    "    Based on the gini index or entropy, decisoin tree are split at node level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6477c2b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2612570786.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ACE\\AppData\\Local\\Temp\\ipykernel_18356\\2612570786.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    64. Explain the concept of information gain in decision trees.\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "64. Explain the concept of information gain in decision trees.\n",
    "\n",
    "Ans: The amount of information improved in the nodes before splitting them for making further decision.\n",
    "    It is the basic criteria to decide whether  a feature should be used to split node or not.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3665d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "65. How do you handle missing values in decision trees?\n",
    "\n",
    "Ans:\n",
    "    In the preprocessing step we can handle the null values.\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d751e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "66. What is pruning in decision trees and why is it important?\n",
    "\n",
    "Ans: \n",
    "    Pruning is a method which stops the decision tree from growing to it's full length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "67. What is the difference between a classification tree and a regression tree?\n",
    "\n",
    "Ans: \n",
    "    \n",
    "    Classification trees are used when the dataset needs to be split into classes that belong to the response variable.\n",
    "    \n",
    "    Regression trees are used when the response variable is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "68. How do you interpret the decision boundaries in a decision tree?\n",
    "\n",
    "Ans: \n",
    "\n",
    "    Decision boundary means that we are dividing or separating the data points with the help of line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "69. What is the role of feature importance in decision trees?\n",
    "\n",
    "Ans: \n",
    "    \n",
    "    It helps us to understand which feature is important for the decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "70. What are ensemble techniques and how are they related to decision trees?\n",
    "\n",
    "Ans: -  Below are the ensemble techniques:\n",
    "        1. BAGGing, or Bootstrap AGGregating\n",
    "        2. Boosting\n",
    "        3.Stacking\n",
    "        4. Voting\n",
    "    \n",
    "    \n",
    "    Decison Tree is one of the example of the BAGGING or BOOTSTRAP AGGREgating.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c724c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "71. What are ensemble techniques in machine learning?\n",
    "\n",
    "Ans: -  Below are the ensemble techniques:\n",
    "        1. BAGGing, or Bootstrap AGGregating\n",
    "        2. Boosting\n",
    "        3.Stacking\n",
    "        4. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "72. What is bagging and how is it used in ensemble learning?\n",
    "\n",
    "Ans: \n",
    "    Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly \n",
    "    used to reduce variance within a noisy dataset. In bagging, a random sample of data in a training set is\n",
    "    selected with replacement—meaning that the individual data points can be chosen more than once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d745061",
   "metadata": {},
   "outputs": [],
   "source": [
    "73. Explain the concept of bootstrapping in bagging.\n",
    "\n",
    "Ans:- \n",
    "    Bootstrapping is a sampling method, where a sample is chosen out of a set, using the replacement method\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "74. What is boosting and how does it work?\n",
    "\n",
    "Ans:- \n",
    "    In boosting, a random sample of data is selected, fitted with a model and \n",
    "    then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1dadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "75. What is the difference between AdaBoost and Gradient Boosting?\n",
    "\n",
    "Ans:-\n",
    "    AdaBoost is the first designed boosting algorithm with a particular loss function.\n",
    "    Gradient Boosting is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "76. What is the purpose of random forests in ensemble learning?\n",
    "\n",
    "Ans:\n",
    "    Random forest algorithm is an ensemble learning technique combining numerous classifiers to enhance a model's performance.\n",
    "    Random Forest is a supervised machine-learning algorithm made up of decision trees. \n",
    "    Random Forest is used for both classification and regression problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "77. How do random forests handle feature importance?\n",
    "\n",
    "Ans:-\n",
    "    The final feature importance, at the Random Forest level, is it's average over all the trees. \n",
    "    The sum of the feature's importance value on each trees is calculated and divided by the total number of trees\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ea847",
   "metadata": {},
   "outputs": [],
   "source": [
    "78. What is stacking in ensemble learning and how does it work?\n",
    "\n",
    "Ans:- \n",
    "        Stacking is one of the most popular ensemble machine learning techniques \n",
    "        used to predict multiple nodes to build a new model and improve model performance\n",
    "        \n",
    "        Stacking enables us to train multiple models to solve similar problems, \n",
    "        and based on their combined output, it builds a new model with improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "79. What are the advantages and disadvantages of ensemble techniques?\n",
    "\n",
    "    Ans:-   Ensemble methods offer several advantages over single models, such as improved accuracy and performance,\n",
    "        especially for complex and noisy problems. They can also reduce the risk of overfitting and \n",
    "        underfitting by balancing the trade-off between bias and variance, \n",
    "        and by using different subsets and features of the data.\n",
    "        \n",
    "        Ensemble methods have some drawbacks and challenges, such as being computationally expensive and\n",
    "        time-consuming due to the need for training and storing multiple models, and combining their outputs.\n",
    "        This can increase the complexity and memory requirements of the system. Additionally,\n",
    "        they can be difficult to interpret and explain, as they involve multiple layers of abstraction and aggregation,\n",
    "        which can obscure the logic and reasoning behind the predictions. Furthermore, they can be prone to overfitting and\n",
    "        underfitting if the base models are too weak or too strong, or if the aggregation method is too simple or \n",
    "        too complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9245c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "80. How do you choose the optimal number of models in an ensemble?\n",
    "\n",
    "Ans:  We can choose the optimal number of models in an ensemble based on the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
